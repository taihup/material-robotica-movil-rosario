\begin{frame}
    \frametitle{Filtro de Partículas (Particle Filter)}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}
    \footnotesize
    \begin{itemize}
        \item Con EKF estamos restringidos a distribuciones Gaussianas.
        \item Cuando usamos EKF obtenemos una Distibuión Gaussiana que describe dónde se encuentra el robot.
        \item En Particle Filter utilizamos partículas o hipótesis que describen dónde podría estar el robot.
        \item En vez de tener una forma paramétrica como es EKF, que describimos la distribución de probabilidad con los parámetros media $\mu$ y covarianza $\covariance$. Partible Filter utiliza muestras no-paramétricas como hipótesis sobre dónde el robot podría estar.
    \end{itemize}
    
    
   	\begin{center}
        \movie[loop]{\includegraphics[width=0.4\columnwidth]{images/particle_filter/particle_filter_video.jpg}}{videos/particle_filter.mp4}
    \end{center}
    
    \note{Vídeo extraído de https://rse-lab.cs.washington.edu/projects/mcl/animations/global-floor.gif}
    
\end{frame}

\begin{frame}
    \frametitle{Aproximación de una Función}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}
    \footnotesize
    
    \begin{itemize}
        \item Objetivo: Poder estimar cualquier \textbf{distribución de probabilidad arbitraria}.
    \end{itemize}
    
    \begin{center}
    \includegraphics[width=0.5\columnwidth]{./images/particle_filter/arbitrary_distribution.pdf}
    \end{center}
    
\end{frame}

\begin{frame}
    \frametitle{Utilizando Muestras (Partículas)}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}
    \footnotesize
    \begin{itemize}
        \item \textbf{Múltiples muestras} para representar una distribución de probabilidad arbitraría
        \item Las muestras son están más agrupadas en algunas áreas en otras menos. La cantidad de partículas por unidad de área describe que tan probable es que el robot se encuentre en esa área.
        \item Cada muestra está acumulando un poco de ``masa de probabilidad''.
        \item Las muestra puede ser vista como una aproximación a la función de densidad de probabilidad (pdf).
        \item Para obtener la pdf, hay que integrar sobre una cierta área de manera de obtener la probabilidad matemática de que el robot se encuentre en dicha área.
    \end{itemize}
    
    \begin{center}
    \includegraphics[width=0.5\columnwidth]{./images/particle_filter/arbitrary_distribution_samples.pdf}
    \end{center}
    
\end{frame}

\begin{frame}
    \frametitle{Utilizando Muestras con Peso}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}
    \footnotesize
    \begin{itemize}
        \item \textbf{Múltiples muestras con peso} para representar una distribución de probabilidad arbitraría
        \item Es posible reducir el número de muestras que necesitamos, si le agregamos pesos a cada muestra
        \item Mientras más peso tiene una muestra, más masa de probabilidad hay en esa región
        \item Los pesos de todas las partículas juntas deben sumar 1
        \item Al inicio, podríamos agregarle a cada muestra un peso uniforme. Por ejemplo, si tenemos $n$ muestras, entonces cada muestra tiene peso $\frac{1}{n}$
    \end{itemize}
    
    \begin{center}
        \includegraphics[width=0.5\columnwidth]{./images/particle_filter/arbitrary_distribution_weighted_samples.pdf}
    \end{center}
    
\end{frame}

\begin{frame}
    \frametitle{Filtro de Partículas (Particle Filter)}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}
    
    \footnotesize
    \begin{itemize}
        \item Notar que es una aproximación de la PDF (\emph{Probabilistic Density Function})
        \item Es importante tener un número de muestras suficientes para poder representar la PDF adecuadamente.
    \end{itemize}
    
    
\end{frame}

\begin{frame}
    \frametitle{Conjunto de Partículas}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}
    
    \begin{itemize}
        \item Conjunto de partículas con peso
            
        \begin{center}
            \includegraphics[width=0.5\columnwidth]{./images/particle_filter/weighted_samples.pdf}
        \end{center}

        \item Las partículas representan la posterior belief dada por
        \begin{equation*}
            p(x) = \sum_{j=1}^{J} w^{[j]} \delta_{x^{[j]}}(x)    
        \end{equation*}
        donde $\delta_{x^{[j]}}(x)$ es la función de Dirac centrada en la ubicación de la partícula $x^{[j]}$.

        \begin{equation*}
            \delta(y) = 
            \begin{cases} 
            \infty, & y = x^{[j]} \\ 
            0, & y \neq x^{[j]} 
            \end{cases};    
        \end{equation*}

        \note{La función tiende a infinito cuando $x=j$ y, para cualquier otro valor de $x$, es igual a 0.}

    \end{itemize}
   
\end{frame}


\begin{frame}
    \frametitle{Partículas para Aproximar}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}
    
    \begin{itemize}
        \item Partículas para aproximar una función
        
        \begin{center}
            \includegraphics[width=0.45\columnwidth]{./images/particle_filter/gaussian_approximation_by_sampling.pdf}
            \includegraphics[width=0.45\columnwidth]{./images/particle_filter/particles_for_approximation.pdf}
        \end{center}

        \item Más partículas caen en una región, más alta es la probabilidad de la región
    \end{itemize}
    
    \begin{center}
        \alert{¿Cómo obtener dichas muestras?}
    \end{center}

\end{frame}

\begin{frame}
    \frametitle{Una Forma Cerrada de Muestreo es solo posible para Pocas Distribuciones}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}

    \begin{itemize}
        \item Ejemplo: Distribución Gaussiana
        
        \begin{center}
            \includegraphics[width=0.5\columnwidth]{./images/particle_filter/gaussian_approximation_by_sampling.pdf}
        \end{center}
        
        \begin{equation*}
            x \leftarrow \frac{1}{2} \sum_{i=1}^{12} \text{rand}(-\sigma, \sigma)
        \end{equation*}
    \end{itemize}

    ¿Cómo samplear utilizando otra distribución?

    \note{Técnica de rejection sampling. No sé utiliza en particle filter porque es una técnica muy ineficiente.}

    \note{Técnica Importance Sampling Principle}

\end{frame}
    


\begin{frame}
    \frametitle{Principio de muestreo de importancia}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}

    \begin{itemize}
        \item Podemos usar una distribución diferente $\pi$ para generar muestras de $f$
        \item Considere las ``diferencias entre $\pi$ y $f$'' usando un peso $w = f(x) / \pi(x)$
        \item Target $f$
        \item Proposal $\pi$
        \item Precondición:
        $f(x) > 0 \implies \pi(x) > 0$
        \begin{center}
        \includegraphics[width=0.45\textwidth]{./images/particle_filter/importance_sampling_principle.pdf}
        \end{center}
    \end{itemize}
\end{frame}
    
\begin{frame}
    \frametitle{Filtro de Partículas}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}

    \begin{itemize}
        \item Filtro Bayesiano recursivo
        \item Enfoque no paramétrico
        \item Modela la distribución mediante muestras
        \item \textbf{Predicción}: extraer de la distribución propuesta
        \item \textbf{Corrección}: ponderación por la relación entre la distribución objetivo y la propuesta
        \item \alert{¡Cuantas más muestras usemos, mejor será la estimación!}
    \end{itemize}
\end{frame}
    
\begin{frame}
    \frametitle{Algoritmo de Filtro de Partículas}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}

    \begin{enumerate}
        \item Muestrear las partículas utilizando la distribución propuesta.
        \begin{equation*}
            x_t^{[j]} \sim proposal(x_t | \ldots)
        \end{equation*}
        \item Calcular los pesos de importancia
        \begin{equation*}
            w_t^{[j]} = \frac{target(x_t^{[j]})}{proposal(x_t^{[j]})}
        \end{equation*}
        \item Resampling: Tomar la partícula $i$ con probabilidad $w_t^{[j]}$ y repetir $J$ veces 
    \end{enumerate}
    \note{Reemplazar muestras improbables por otras más probables}
\end{frame}

\begin{frame}
    \frametitle{Algoritmo de Filtro de Partículas}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}

    \begin{algorithmic}[1]
    \Procedure{ParticleFilter}{$\mathcal{X}_{t-1}, u_{t}, z_{t}$}:
    \State $\bar{\mathcal{X}}_t = \mathcal{X}_t = \emptyset$
    \For{$j = 1$ to $J$}
        \State sample $x_t^{[j]} \sim \pi(x_t)$
        \State $w_t^{[j]} = \dfrac{p(x_t^{[j]})}{\pi(x_{t}^{[j]})}$
        \State $\bar{\mathcal{X}}_t = \bar{\mathcal{X}}_t + \langle x_t^{[j]}, w_t^{[j]}\rangle$
    \EndFor
    \For{$j = 1$ to $M$}
        \State Draw $i$ with probability $\propto w_t^{[i]}$
        \State Add $x_t^{[i]}$ to $\mathcal{X}_t$
    \EndFor
    \State return $\mathcal{X}_t$
    \EndProcedure
    \end{algorithmic}
\end{frame}


\begin{frame}
    \frametitle{Monte Carlo Localization}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}

    Monte Carlo Localization: Filtro de Partículas para la localización de un robot

\end{frame}


% \begin{frame}
%     \frametitle{Monte Carlo Localization}

%     \begin{center}
%         \includegraphics[width=0.37\textwidth]{./images/particle_filter/monte_carlo_localization_example.pdf}
%     \end{center}

% \end{frame}

\begin{frame}
    \frametitle{Monte Carlo Localization}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}

    \begin{itemize}
        \item Cada partícula es una hipótesis de la pose
        \item Proposal es el motion model
        \begin{equation*}
            x_t^{[j]} \sim p(x_t \, | \, x_{t-1}, u_t)
        \end{equation*}
        \item Corrección vía el observation model
        \begin{equation*}
            w_t^{[j]} = \frac{target}{proposal} \propto p(z_t \, | \, x_t, m)
        \end{equation*}
    \end{itemize}
\end{frame}

    
\begin{frame}
    \frametitle{Filtro de Partículas para Localización}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}

    \begin{algorithmic}[1]
        \Procedure{ParticleFilter}{$\mathcal{X}_{t-1}, u_{t}, z_{t}$}
        \State $\bar{\mathcal{X}}_t = \mathcal{X}_t = \emptyset$
        \For{$j = 1$ to $J$}
            \State Sample $x_t^{[j]} \sim p(x_t \, | \, u_t, x_{t-1}^{[j]})$
            \State $w_t^{[j]} = p(z_t \, | \, x_t^{[j]})$
            \State $\bar{\mathcal{X}}_t = \bar{\mathcal{X}}_t + \langle x_t^{[j]}, w_t^{[j]}\rangle$
        \EndFor
        \For{$i = 1$ to $J$}
            \State Draw $i \in 1,\ldots,J$ with probability $\propto w_t^{[i]}$
            \State Add $x_t^{[i]}$ to $\mathcal{X}_t$
        \EndFor
        \State return $\mathcal{X}_t$
    \EndProcedure
    \end{algorithmic}
\end{frame}
    
\begin{frame}
    \frametitle{Monte Carlo Localization - Paso de Corrección}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}

    \begin{center}
        \includegraphics[width=0.8\textwidth]{./images/particle_filter/monte_carlo_correction.pdf}
    \end{center}

\end{frame}

\begin{frame}
    \frametitle{Monte Carlo Localization - Remuestreo y Predicción}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}

    \begin{center}
        \includegraphics[width=0.8\textwidth]{./images/particle_filter/monte_carlo_resample_and_predict.pdf}
    \end{center}

\end{frame}

\begin{frame}
    \frametitle{Monte Carlo Localization - Paso de Corrección 2}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}

    \begin{center}
        \includegraphics[width=0.8\textwidth]{./images/particle_filter/monte_carlo_correction2.pdf}
    \end{center}

\end{frame}

\begin{frame}
    \frametitle{Monte Carlo Localization - Remuestreo y Predicción 2}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}

    \begin{center}
        \includegraphics[width=0.8\textwidth]{./images/particle_filter/monte_carlo_resample_and_predict2.pdf}
    \end{center}

\end{frame}


\begin{frame}
    \frametitle{Resampling}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}

    \begin{itemize}
        \item Tomar la partícula $i$ con probabilidad $w_t^{[i]}$. Repetir $J$ veces.
        \item Informalmente: ``Reemplazar muestras improbables por otras más probables''
        \item Supervivencia del más apto
        \item ``Truco'' para evitar que muchas muestras cubran estados improbables
        \item Necesario, ya que tenemos un número limitado de muestras
    \end{itemize}
\end{frame}
    
\begin{frame}
    \frametitle{Métodos de Resampling}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}

    \begin{overlayarea}{\textwidth}{\textheight}
        
        \only<1>{
            \begin{center}
                \includegraphics[width=0.35\textwidth]{./images/particle_filter/resampling_rulette_wheel1.pdf}
            \end{center}
        }
        \only<2>{
            \begin{center}
                \includegraphics[width=0.35\textwidth]{./images/particle_filter/resampling_rulette_wheel2.pdf}
            \end{center}
        }
        \only<3>{
            \begin{center}
                \includegraphics[width=0.35\textwidth]{./images/particle_filter/resampling_rulette_wheel3.pdf}
            \end{center}
        }
        \only<3>{
            \begin{itemize}
                \item Roulette Wheel
                \item Búsqueda binaria para saber en qué bucket cae la bola ($O(J \log(J))$)
            \end{itemize}
            \note{Los buckets de la ruleta representan los pesos de las partículas. Mientras más grande el bucket, más probable es que esta partícula sea seleccionada.}
            \note{Tenemos que hacerlo J veces. Tenemos que encontrar dónde cae la bola. Esto lo podemos hacer con binary-search. La suma de todos los pesos de la ruleta es 1. Si tiramos un número random entre 0 y 1 entonces con búsqueda binaria podemos saber en qué bucket cae.}
        }
    \end{overlayarea}
\end{frame}

\begin{frame}
    \frametitle{Métodos de Resampling}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}

    \begin{overlayarea}{\textwidth}{\textheight}
        \only<1>{
            \begin{center}
                \includegraphics[width=0.35\textwidth]{./images/particle_filter/resampling_stochastic_universal_sampling1.pdf}
            \end{center}
        }
        \only<2>{
            \begin{center}
                \includegraphics[width=0.35\textwidth]{./images/particle_filter/resampling_stochastic_universal_sampling2.pdf}
            \end{center}
        }

        \only<2>{

        \begin{itemize}
            \item Stochastic universal sampling (utilizando $J$ flechas equidistantes)
            \item También llamado \emph{Low-Variance Resampling} (evita que las partículas se concentren rápidamente)
            \item $O(J)$
        \end{itemize}
        \note{Utilizando on flechas y poniendolas equidistantes. Rotamos todas juntas y elejimos de a n partículas. Por tanto cuando, tiro un número random ahora se seleccionan las J partículas de una.}
        \note{Tiene costo computacional lineal porque solo tengo que recorrer los pesos una vez para ver dónde caen todas las flechas.}
        \note{Ejemplo 8 flechas distante 45 grados una de otra.}
        
        }
    \end{overlayarea}
\end{frame}

\begin{frame}
    \frametitle{Resampling}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}

    \begin{itemize}
        \item Muestreo con remplazo (muestreamos tomando una partícula y luego la volvemos a colocar en la bolsa)
        \item Roulette Wheel resampling es fácil de entender pero es suboptimo en la práctica
        \item \alert{¿Qué pasa si todas las partículas tienen el mismo peso?}
        \note{Si todas las partículas tienen el mismo peso, sería como tener un sensor que no me da información.}
        \note{Si todas las partículas tienen el mismo peso, el resampling seleccionará partículas de manera aleatoria y las duplicará, y otras partículas no serán seleccionadas y moriran. Y esto pasa sin que una partícula sea mejor que otra. Esto lleva a que el sistema converja en una localización cualquiera.}
        \note{Por tanto, si todas las partículas tienen el mismo peso entonces no tiene sentido escoger una por encima de otra.}

        \note{
            https://robotics.stackexchange.com/questions/16093/why-does-the-low-variance-resampling-algorithm-for-particle-filters-work

            TLDR; A particle filter’s convergence rate is inversely proportional to the variance in the parents’ offspring counts. Low variance means fast convergence.

            NOTE: Below, I discuss (but never explicitly mention) the concept of variance effective population size.

            The effectiveness of this resampling strategy makes a lot of sense when you consider that the particle filter is, at its core, an evolutionary algorithm (EA). All EAs tend to lose diversity because of the random sampling step, at a rate proportional to the variance in how many offspring the parents produce. This effect is known as genetic drift, and it adversely affects biological populations as well. As a result of this diversity loss, the EA prematurely converges to suboptimal solutions. This is bad news.

            Intuitively, genetic drift makes sense. When parents are chosen at random (the most common setup), those with low fitness/quality are likely to get skipped and produce zero offspring and be eliminated from the gene pool, thus reducing the population’s diversity. Now, the rate at which natural selection improves a population’s fitness is directly proportional to the population’s diversity—diversity is literally the fuel that drives natural selection. Genetic drift reduces the the diversity, thus decreasing the rate at which the population’s fitness can improve and causing the aforementioned bad news.

            Let’s now look at the low-variance resampling method. This method gives almost every parent exactly the number of offspring that they would be expected to get with the random sampling, without the extra uncertainty (variance). This reduces genetic drift and greatly increases the efficiency with which the particle filter can improve its solution and/or adapt to changing condition
        }

    \end{itemize}
\end{frame}


\begin{frame}
    \frametitle{Idea de Low Variance Resampling}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}

    \begin{center}
        \only<1>{\includegraphics[width=0.7\textwidth]{./images/particle_filter/low_variance_resampling.pdf}}
        \only<2>{\includegraphics[width=0.7\textwidth]{./images/particle_filter/low_variance_resampling2.pdf}}
    \end{center}

    \begin{enumerate}
        \item<1-> Tomamos un valor random $r$ entre 0 y $\dfrac{1}{j}$
        \item<2> Tomamos $J-1$  partículas en $\dfrac{1}{J}$ pasos (basado en el peso acumulado)
    \end{enumerate}

\end{frame}

\begin{frame}
    \frametitle{Low Variance Resampling}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}

    \begin{center}
        \only<1>{\includegraphics[width=0.7\textwidth]{./images/particle_filter/low_variance_resampling3.pdf}}
        \only<2>{\includegraphics[width=0.7\textwidth]{./images/particle_filter/low_variance_resampling4.pdf}}
    \end{center}

    \begin{enumerate}
        \item<1-> Tomamos un valor random $r$ entre 0 y $\dfrac{1}{j}$
        \item<2>
        \begin{algorithmic}[1]
            \For{$j = 1$ to $J$}
                \State $U = r + (j - 1)  \dfrac{1}{J}$
                \While{$\left(U > cum[i]\right)$}
                    \State $i++$
                \EndWhile
                \State Add $x_t^{[i]}$ to $\bar{\mathcal{X}}_t$
            \EndFor
        \end{algorithmic}
        % \begin{fleqn}[\parindent]
        %     \begin{align*}
        %         for &(j=1 \dots J)\\
        %             &U = r + j \dfrac{1}{J}\\
        %             &while (U > cum[i]) \quad i++;\\
        %             &pick\_particle(i)
        %     \end{align*}
        % \end{fleqn}
    \end{enumerate}
    
\end{frame}

\begin{frame}
    \frametitle{Low Variance Resampling}

    \begin{algorithmic}[1]
        \Procedure{Low Variance Resampling}{$\mathcal{X}_{t}$,$\mathcal{W}_{t}$}
        \State $\bar{\mathcal{X}}_t = \emptyset$
        \State $r = \text{rand}(0; J^{-1})$
        \State $c = w_t^{[1]}$
        \State $i = 1$
        \For{$j = 1$ to $J$}
            \State $U = r + (j - 1)  J^{-1}$
            \While{$U > c$}
                \State $i = i + 1$
                \State $c = c + w_t^{[i]}$
            \EndWhile
            \State Add $x_t^{[i]}$ to $\bar{\mathcal{X}}_t$
        \EndFor
        \State Return $\bar{\mathcal{X}}_t$
        \EndProcedure
    \end{algorithmic}

    % \begin{tikzpicture}[remember picture,overlay]
    %     \node[xshift=-5.5cm,yshift=0.5cm] at (current page.east) { \includegraphics[width=0.6\textwidth]{./images/particle_filter/low_variance_resampling.pdf}};
    % \end{tikzpicture}

\end{frame}

\begin{frame}
    \frametitle{Low Variance Resampling}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}

    \begin{itemize}
        \item Realiza un remuestreo que mantiene las muestras en el caso que tengan pesos iguales
        \item Es más rápido que el remuestreo con roulette wheel: $\mathcal{O}(J)$ vs. $\mathcal{O}(J \log J)$
        \item \alert{Utilizaremos siempre Low Variance Resampling!}
    \end{itemize}
\end{frame}


\begin{frame}
    \frametitle{Desventajas de Particle Filter}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}

    \begin{itemize}
        \item No escala bien para espacios de alta dimensionalidad
        \note{PF se hace muy caro computacionalmente ya que necesitaremos muchas partículas para cubrir la distribución de probabilidad. PF funciona bien para bajas dimensiones, hasta 4 se puede pero más ya requiere tomar ciertas heurísticas para reducir el número de partículas y que estas sean representativas.}
        \note{El número de partículas crece exponencialmente con las dimenciones del estado}
        \item Problemático en situaciones con mucha incertidumbre
        \item \emph{Depletion Problem} (la mayoría de las partículas tienen poco peso)
        \item \note{El Depletion Problem: sucede cuando tenemos muy pocas partículas en comparación a la dimensionalidad del estado, las partículas no cubren las áreas de mayor probabilidad y por tanto mueren, haciendo que el filtro diverja eventualmente.
        Ejemplo: Imagina que tienes 100 partículas rastreando la posición de un robot. Si el robot da un giro brusco, muchas partículas tendrán pesos bajos porque no predicen bien el movimiento. Tras el resampling, solo unas pocas partículas "sobrevivirán", y el filtro perderá diversidad, afectando la estimación futura.}
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Ventajas}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}

    \begin{itemize}
        \item Puede trabajar con distribuciones no Gaussianas
        \item Funciona bien en espacios de baja dimensionalidad
        \item Puede manejar ambiguedades en la asociación de los datos \note{Podemos hacer que cada partícula tenga su propia forma de asociar datos. Como no hay incertidumbre asociada a esto, podemos hacer decisiones dependientes a cada partícula y ver qué partícula sobrevive.}
        \item Puede incorporar fácilmente diferentes modalidades de sensado \note{Podemos incorporar diferentes modalidades de sensado tan solo multiplicando el peso con el peso computado de otro sensor}
        \item Robusto \note{Robusto porque incluso cuando los modelos no sean perfectos será capaz de computar buenas belief}
        \item Fácil de implementar
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Resumen – Particle Filter}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}

    \begin{itemize}
        \item Los filtros de partículas son filtros bayesianos recursivos y no paramétricos
        \item El Posterior Belief se representa mediante un conjunto de muestras ponderadas
        \item No se limita a Distribuciones Gaussianas
        \item Proposal para extraer muestras en $t+1$
        \item Peso para tener en cuenta las diferencias entre la proposal y el target
        \item El arte está en diseñar modelos de movimiento y sensado adecuados
    \end{itemize}
\end{frame}
    
\begin{frame}
    \frametitle{Resumen – Localización con PF}
    \note{Información extraída de Vídeo de Cyrill Stachniss https://youtu.be/MsYlueVDLI0}

    \begin{itemize}
        \item Las partículas se propagan según el modelo de movimiento
        \item Se ponderan según la probabilidad de la observación
        \item Se denomina Localización de Monte Carlo (MCL)
        \item La MCL es un gold standard para la localización de robots móviles en entornos \emph{indoor}
    \end{itemize}
\end{frame}